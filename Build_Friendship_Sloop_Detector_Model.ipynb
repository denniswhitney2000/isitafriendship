{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friendship Sloop Detector Model\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to build and train a deep learning model to detect Friendship Sloops in images. The model is based on the ResNet50 architecture and uses data augmentation techniques to improve generalization. The notebook includes steps for data preprocessing, model definition, training, and evaluation.\n",
    "\n",
    "## Prerequisites\n",
    "Before running this notebook, ensure you have the following prerequisites:\n",
    "\n",
    "- Python 3.6 or higher\n",
    "- TensorFlow 2.x\n",
    "- Keras\n",
    "- OpenCV\n",
    "- Matplotlib\n",
    "- dotenv\n",
    "- scipy\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "### 1. Clone the Repository: \n",
    "\n",
    "Clone the repository containing this notebook and navigate to the directory.\n",
    "Be sure to create the virtual environment.\n",
    "\n",
    "```bash\n",
    "git clone <repository_url>\n",
    "cd <repository_directory>\n",
    "\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "``` \n",
    "\n",
    "### 2. Install Dependencies:\n",
    "\n",
    "Install the required Python packages using pip.\n",
    "\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 3. Set Up Environment Variables:\n",
    "\n",
    "Create a `.env` file in the root directory and define the following environment variables:\n",
    "\n",
    "```bash\n",
    "DATA_DIR=path/to/your/data\n",
    "BATCH_SIZE=32\n",
    "NUM_EPOCHS=10\n",
    "MODEL_PATH=path/to/save/model\n",
    "```\n",
    "\n",
    "Going forward, use the notebook service that best suits your needs to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "Imports the necessary libraries for data preprocessing, model building, with metrics and environment management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import cv2\n",
    "import os\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress only the single warning from urllib3.\n",
    "import urllib3\n",
    "urllib3.disable_warnings(category=urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Load environment variables from the .env file (if present)\n",
    "load_dotenv()\n",
    "\n",
    "# Define the config class\n",
    "class CFG:\n",
    "\n",
    "    # Define the directory to store the images\n",
    "    DATA_DIR = Path(os.environ['DATA_DIR'])\n",
    "    \n",
    "    # Set the number of batchs for processing\n",
    "    BATCH_SIZE = int(os.environ['BATCH_SIZE'])\n",
    "\n",
    "    # Epocs for model training\n",
    "    NUM_EPOCHS = int(os.environ['NUM_EPOCHS'])\n",
    "    \n",
    "    MODEL_PATH = Path(os.environ['MODEL_PATH'])\n",
    "    \n",
    "pprint.pprint(CFG.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Configures the data augmentation and preprocessing using ImageDataGenerator. It defines training and validation data generators that load images from the specified directory and apply transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = CFG.DATA_DIR\n",
    "img_size = 224 # 128  # Adjust based on image size\n",
    "batch_size = CFG.BATCH_SIZE\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,  # Split for training/validation\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition\n",
    "This section defines the model architecture using the ResNet50 base model with custom classification layers. The base model's layers are frozen to prevent them from being trained and adds multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 with pretrained weights and exclude top layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze all layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "print(f'Made: {x}')\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile the model with additional metrics\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# # Debug: Show the model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Show sample of loaded images\n",
    "\n",
    "Shows a 3x3 grid of the first 9 images loaded from `CFG.DATA_DIR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a list of image file paths\n",
    "dir = CFG.DATA_DIR / 'train/friendship_sloop'\n",
    "\n",
    "# Get a list of image file paths\n",
    "image_files = [os.path.join(dir, f) for f in os.listdir(dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "# Randomly select 9 images\n",
    "random_images = random.sample(image_files, 9)\n",
    "\n",
    "# Display a 3x3 grid of images\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for img_path, ax in zip(random_images, axes):\n",
    "    print(f'Processing image: {img_path}')\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(os.path.basename(img_path))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "This section trains the model using the training and validation data generators. The training process is monitored using validation accuracy and loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=CFG.NUM_EPOCHS,\n",
    "    validation_data=val_gen\n",
    ")\n",
    "print(f\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate and the Model\n",
    "\n",
    "This section evaluates the model's performance on the `validation` dataset, then graphicly displays in information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, precision, recall = model.evaluate(val_gen)\n",
    "\n",
    "# Create the metrics object\n",
    "metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'Loss': loss\n",
    "}\n",
    "\n",
    "# Convert metrics to a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics, index=[0])\n",
    "\n",
    "# Display metrics as a table\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df)\n",
    "plt.title('Model Performance Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Function to generate HTML explanation\n",
    "def generate_explanation_html(metrics):\n",
    "    explanation_html = f\"\"\"\n",
    "    <h3>Explanation of Metrics</h3>\n",
    "    <ol>\n",
    "        <li><strong>Accuracy</strong>:\n",
    "            <ul>\n",
    "                <li><strong>Definition</strong>: The proportion of correctly classified instances out of the total instances.</li>\n",
    "                <li><strong>Good Value</strong>: Generally, an accuracy above 0.80 (80%) is considered good, but this can vary depending on the complexity of the task and the dataset.</li>\n",
    "                <li><strong>Current Value</strong>: {metrics['Accuracy']:.2f}</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Precision</strong>:\n",
    "            <ul>\n",
    "                <li><strong>Definition</strong>: The proportion of true positive predictions out of all positive predictions (i.e., the accuracy of positive predictions).</li>\n",
    "                <li><strong>Good Value</strong>: A precision above 0.75 (75%) is typically considered good. High precision indicates that the model has a low false positive rate.</li>\n",
    "                <li><strong>Current Value</strong>: {metrics['Precision']:.2f}</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Recall</strong>:\n",
    "            <ul>\n",
    "                <li><strong>Definition</strong>: The proportion of true positive predictions out of all actual positives (i.e., the ability of the model to find all relevant instances).</li>\n",
    "                <li><strong>Good Value</strong>: A recall above 0.75 (75%) is generally considered good. High recall indicates that the model has a low false negative rate.</li>\n",
    "                <li><strong>Current Value</strong>: {metrics['Recall']:.2f}</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Loss</strong>:\n",
    "            <ul>\n",
    "                <li><strong>Definition</strong>: A measure of how well the model's predictions match the actual labels. Lower loss values indicate better performance.</li>\n",
    "                <li><strong>Good Value</strong>: The acceptable loss value depends on the specific loss function used and the problem context. Generally, lower values are better.</li>\n",
    "                <li><strong>Current Value</strong>: {metrics['Loss']:.2f}</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ol>\n",
    "    \"\"\"\n",
    "    return explanation_html\n",
    "\n",
    "# Generate and display the explanation using HTML\n",
    "explanation_html = generate_explanation_html(metrics)\n",
    "display(HTML(explanation_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the model\n",
    "\n",
    "Saves the model to the `CFG.MODEL_PATH` in the `keras` file format, aka and compressed file with the model contained with in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base directory if it doesn't exist\n",
    "base_dir = CFG.MODEL_PATH.parent\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model.save(CFG.MODEL_PATH)\n",
    "print(f'saved { os.path.getsize(CFG.MODEL_PATH) } bytes to {CFG.MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Testing on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = img / 255.0\n",
    "    img = img.reshape(-1, img_size, img_size, 3)\n",
    "    return img\n",
    "\n",
    "# Predict\n",
    "# Directory containing test images\n",
    "test_image_dir = 'images/prediction'\n",
    "\n",
    "# Iterate over all images in the directory\n",
    "for filename in os.listdir(test_image_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        test_image_path = os.path.join(test_image_dir, filename)\n",
    "        \n",
    "        # Show the test image\n",
    "        plt.imshow(Image.open(test_image_path))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # Preprocess and predict\n",
    "        img = preprocess_image(test_image_path)\n",
    "        prediction = model.predict(img)\n",
    "\n",
    "        print(f\"Prediction for {filename}: {prediction}\")\n",
    "        if prediction[0][0] > 0.5:\n",
    "            print(\"Friendship Sloop detected\")\n",
    "        else:\n",
    "            print(\"No Friendship Sloop detected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
