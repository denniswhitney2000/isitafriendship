{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friendship Sloop Detector Model\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to build and train a deep learning model to detect Friendship Sloops in images. The model is based on the ResNet50 architecture and uses data augmentation techniques to improve generalization. The notebook includes steps for data preprocessing, model definition, training, and evaluation.\n",
    "\n",
    "## Prerequisites\n",
    "Before running this notebook, ensure you have the following prerequisites:\n",
    "\n",
    "- Python 3.6 or higher\n",
    "- TensorFlow 2.x\n",
    "- Keras\n",
    "- OpenCV\n",
    "- Matplotlib\n",
    "- dotenv\n",
    "- scipy\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "### 1. Clone the Repository: \n",
    "\n",
    "Clone the repository containing this notebook and navigate to the directory.\n",
    "Be sure to create the virtual environment.\n",
    "\n",
    "```bash\n",
    "git clone <repository_url>\n",
    "cd <repository_directory>\n",
    "\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "``` \n",
    "\n",
    "### 2. Install Dependencies:\n",
    "\n",
    "Install the required Python packages using pip.\n",
    "\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 3. Set Up Environment Variables:\n",
    "\n",
    "Create a `.env` file in the root directory and define the following environment variables:\n",
    "\n",
    "```bash\n",
    "DATA_DIR=path/to/your/data\n",
    "BATCH_SIZE=32\n",
    "NUM_EPOCHS=10\n",
    "MODEL_PATH=path/to/save/model\n",
    "```\n",
    "\n",
    "Going forward, use the notebook service that best suits your needs to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "Imports the necessary libraries for data preprocessing, model building, with metrics and environment management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import cv2\n",
    "import os\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress only the single warning from urllib3.\n",
    "import urllib3\n",
    "urllib3.disable_warnings(category=urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Load environment variables from the .env file (if present)\n",
    "load_dotenv()\n",
    "\n",
    "# Define the config class\n",
    "class CFG:\n",
    "\n",
    "    # Define the directory to store the images\n",
    "    DATA_DIR = Path(os.environ['DATA_DIR'])\n",
    "    \n",
    "    # Set the number of batchs for processing\n",
    "    BATCH_SIZE = int(os.environ['BATCH_SIZE'])\n",
    "\n",
    "    # Epocs for model training\n",
    "    NUM_EPOCHS = int(os.environ['NUM_EPOCHS'])\n",
    "    \n",
    "    # Where to save the generated model\n",
    "    MODEL_PATH = Path(os.environ['MODEL_PATH'])\n",
    "    \n",
    "    # Default image size for the model\n",
    "    IMAGE_SIZE = int(os.environ['IMAGE_SIZE'])\n",
    "    \n",
    "    # Generate a random number for the seed\n",
    "    SEED = randrange(1000)\n",
    "    \n",
    "pprint.pprint(CFG.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Display Random Image Set\n",
    "\n",
    "Displays a random sample of images from `{CFG.DATA_DIR}/train/` in a 3x3 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image  # Import Image from PIL\n",
    "\n",
    "# Define the source path\n",
    "src_path = f\"{CFG.DATA_DIR}/train/\"\n",
    "sub_class = os.listdir(src_path)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "path = os.path.join(src_path,sub_class[0])\n",
    "\n",
    "# List all files in the directory\n",
    "all_files = []\n",
    "for subdir, _, files in os.walk(src_path):\n",
    "    for file in files:\n",
    "        all_files.append(os.path.join(subdir, file))\n",
    "\n",
    "# Select 9 random files\n",
    "random_files = random.sample(all_files, 9)\n",
    "\n",
    "# Display the selected files\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for img_path, ax in zip(random_files, axes):\n",
    "    img = Image.open(img_path)\n",
    "    pth = str(Path(img_path).parent).replace(str(src_path), '')\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title( f'{pth} : {os.path.basename(img_path)}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Configures the data augmentation and preprocessing using ImageDataGenerator. \n",
    "\n",
    "It defines training, validation and test data generators that load images from the specified directory and apply transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the training data\n",
    "src_path_train = f\"{CFG.DATA_DIR}/train/\"\n",
    "# Path to the test data\n",
    "src_path_test = f\"{CFG.DATA_DIR}/test/\"\n",
    "\n",
    "# Build the training and test data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1 / 255.0,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.05,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        validation_split=0.20\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "print(f'Procesing training data from: {src_path_train}')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=src_path_train,\n",
    "    target_size= (CFG.IMAGE_SIZE, CFG.IMAGE_SIZE), # target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=CFG.BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "print(f'{len(train_generator.filenames)} : {sorted(train_generator.filenames)}')\n",
    "print('-' * 50)\n",
    "\n",
    "print(f'Procesing validation data from: {src_path_train}')\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    directory=src_path_train,\n",
    "    target_size= (CFG.IMAGE_SIZE, CFG.IMAGE_SIZE), # target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=CFG.BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "print(f'{len(valid_generator.filenames)} : {valid_generator.filenames}')\n",
    "print('-' * 50)\n",
    "\n",
    "print(f'Procesing test data from: {src_path_test}')\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=src_path_test,\n",
    "    target_size= (CFG.IMAGE_SIZE, CFG.IMAGE_SIZE), # target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "print(f'{len(test_generator.filenames)} : {test_generator.filenames}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filesystem accounting\n",
    "\n",
    "Code block to find the number of files in the given directory to compare against the loaded image values from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the class indices\n",
    "class_indices = train_generator.class_indices\n",
    "class_names = list(class_indices.keys())\n",
    "print(f'Class names: {class_names}')\n",
    "print('-' * 50)\n",
    "\n",
    "# Count the number of instances for each class in the training set\n",
    "train_counts = np.bincount(train_generator.classes)\n",
    "val_counts = np.bincount(valid_generator.classes)\n",
    "test_counts = np.bincount(test_generator.classes)\n",
    "\n",
    "# Print the counts for each class\n",
    "print(f\"Training set class distribution: {dict(zip(class_names, train_counts))}\")\n",
    "print(f\"Validation set class distribution: {dict(zip(class_names, val_counts))}\")\n",
    "print(f\"Test set class distribution: {dict(zip(class_names, test_counts))}\")\n",
    "print('-' * 50)\n",
    "\n",
    "# Verify file counts on the filesystem\n",
    "def count_files_in_directory(directory):\n",
    "    file_counts = {}\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir_name in dirs:\n",
    "            class_dir = os.path.join(root, dir_name)\n",
    "            file_counts[dir_name] = len([f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))])\n",
    "    return file_counts\n",
    "\n",
    "train_file_counts = count_files_in_directory(src_path_train)\n",
    "test_file_counts = count_files_in_directory(src_path_test)\n",
    "\n",
    "print(f\"Filesystem training set class distribution: {train_file_counts}\")\n",
    "print(f\"Filesystem test set class distribution: {test_file_counts}\")\n",
    "\n",
    "# Ensure the counts arrays are the same length as the number of classes\n",
    "if len(train_counts) < len(class_names):\n",
    "    train_counts = np.append(train_counts, [0] * (len(class_names) - len(train_counts)))\n",
    "if len(val_counts) < len(class_names):\n",
    "    val_counts = np.append(val_counts, [0] * (len(class_names) - len(val_counts)))\n",
    "if len(test_counts) < len(class_names):\n",
    "    test_counts = np.append(test_counts, [0] * (len(class_names) - len(test_counts)))\n",
    "\n",
    "# Plot the class distribution for the training, validation, and test sets\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(class_names))\n",
    "\n",
    "plt.bar(index, train_counts, bar_width, color='blue', alpha=0.7, label='Training Set')\n",
    "plt.bar(index + bar_width, val_counts, bar_width, color='green', alpha=0.7, label='Validation Set')\n",
    "plt.bar(index + 2 * bar_width, test_counts, bar_width, color='red', alpha=0.7, label='Test Set')\n",
    "\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.xticks(index + bar_width, class_names)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Definition\n",
    "\n",
    "This section defines the model architecture using the ResNet50 base model with custom classification layers. The base model's layers are frozen to prevent them from being trained and adds multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 with pretrained weights and exclude top layers\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(CFG.IMAGE_SIZE, CFG.IMAGE_SIZE, 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "print(f'Made: {x}')\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile the model with additional metrics\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator,\n",
    "    epochs=CFG.NUM_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate and the Model\n",
    "\n",
    "This section evaluates the model's performance on the `validation` dataset, then graphicly displays in information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, precision, recall = model.evaluate(valid_generator)\n",
    "\n",
    "# Create the metrics object\n",
    "metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'Loss': loss\n",
    "}\n",
    "\n",
    "# Convert metrics to a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics, index=[0])\n",
    "\n",
    "# Display metrics as a table\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df)\n",
    "plt.title('Model Performance Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Function to generate HTML explanation\n",
    "def generate_explanation_html(metrics):\n",
    "    explanation_html = f\"\"\"\n",
    "    <h3>Explanation of Metrics</h3>\n",
    "    <ol>\n",
    "        <li><strong>Accuracy</strong>:\n",
    "            <ul>\n",
    "                <li><strong>Definition</strong>: The proportion of correctly classified instances out of the total instances.</li>\n",
    "                <li><strong>Good Value</strong>: Generally, an accuracy above 0.80 (80%) is considered good, but this can vary depending on the complexity of the task and the dataset.</li>\n",
    "                <li><strong>Current Value</strong>: {metrics['Accuracy']:.2f}</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Precision</strong>:\n",
    "            <ul>\n",
    "                <li><strong>Definition</strong>: The proportion of true positive predictions out of all positive predictions (i.e., the accuracy of positive predictions).</li>\n",
    "                <li><strong>Good Value</strong>: A precision above 0.75 (75%) is typically considered good. High precision indicates that the model has a low false positive rate.</li>\n",
    "                <li><strong>Current Value</strong>: {metrics['Precision']:.2f}</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Recall</strong>:\n",
    "            <ul>\n",
    "                <li><strong>Definition</strong>: The proportion of true positive predictions out of all actual positives (i.e., the ability of the model to find all relevant instances).</li>\n",
    "                <li><strong>Good Value</strong>: A recall above 0.75 (75%) is generally considered good. High recall indicates that the model has a low false negative rate.</li>\n",
    "                <li><strong>Current Value</strong>: {metrics['Recall']:.2f}</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Loss</strong>:\n",
    "            <ul>\n",
    "                <li><strong>Definition</strong>: A measure of how well the model's predictions match the actual labels. Lower loss values indicate better performance.</li>\n",
    "                <li><strong>Good Value</strong>: The acceptable loss value depends on the specific loss function used and the problem context. Generally, lower values are better.</li>\n",
    "                <li><strong>Current Value</strong>: {metrics['Loss']:.2f}</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ol>\n",
    "    \"\"\"\n",
    "    return explanation_html\n",
    "\n",
    "# Generate and display the explanation using HTML\n",
    "explanation_html = generate_explanation_html(metrics)\n",
    "display(HTML(explanation_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the model\n",
    "\n",
    "Saves the model to the `CFG.MODEL_PATH` in the `keras` file format, aka and compressed file with the model contained with in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base directory if it doesn't exist\n",
    "base_dir = CFG.MODEL_PATH.parent\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model.save(CFG.MODEL_PATH)\n",
    "print(f'saved { os.path.getsize(CFG.MODEL_PATH) } bytes to {CFG.MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Testing on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (CFG.IMAGE_SIZE, CFG.IMAGE_SIZE))\n",
    "    img = img / 255.0\n",
    "    img = img.reshape(-1, CFG.IMAGE_SIZE, CFG.IMAGE_SIZE, 3)\n",
    "    return img\n",
    "\n",
    "# Predict\n",
    "# Directory containing test images\n",
    "test_image_dir = 'images/prediction'\n",
    "\n",
    "# Iterate over all images in the directory\n",
    "for filename in os.listdir(test_image_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        test_image_path = os.path.join(test_image_dir, filename)\n",
    "        \n",
    "        # Show the test image\n",
    "        plt.imshow(Image.open(test_image_path))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # Preprocess and predict\n",
    "        img = preprocess_image(test_image_path)\n",
    "        prediction = model.predict(img)\n",
    "\n",
    "        print(f\"Prediction for {filename}: {prediction}\")\n",
    "        if prediction[0][0] > 0.5:\n",
    "            print(\"Friendship Sloop detected\")\n",
    "        else:\n",
    "            print(\"No Friendship Sloop detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "Block of code below wil ensure the images are in a valid format. If not, it will convert tot he mode to RGB and save the `target_format`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def verify_and_convert_images(directory, target_format='JPEG'):\n",
    "    jpg_count = 0\n",
    "    other_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    supported_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.ppm', '.tif', '.tiff']\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_ext = os.path.splitext(file)[1].lower()\n",
    "            \n",
    "            if file_ext not in supported_extensions:\n",
    "                print(f\"Unsupported file extension: {file_path}\")\n",
    "                continue\n",
    "            try:\n",
    "\n",
    "                with Image.open(file_path) as img:\n",
    "                    img.verify()  # Verify that it is a valid image\n",
    "                    img.close()\n",
    "    \n",
    "                with Image.open(file_path) as img:\n",
    "                    if img.format != target_format:\n",
    "                        \n",
    "                        print(f\"Processing {other_count} {file_path}\")\n",
    "                        other_count += 1\n",
    "                        print(img.format, img.size, img.mode)\n",
    "                        \n",
    "                        try:\n",
    "                            # Convert to target format if necessary\n",
    "                            img = img.convert('RGB')\n",
    "                            new_file_path = os.path.splitext(file_path)[0] + f'.{target_format.lower()}'\n",
    "                            print(f\"Converted {file_path} to {new_file_path}\")\n",
    "                            \n",
    "                            img.save(new_file_path, target_format)\n",
    "                            print(f'Saved {os.path.getsize(new_file_path)} bytes to {new_file_path}')\n",
    "                            \n",
    "                            os.remove(file_path)\n",
    "                            print(f\"Removed {file_path}\")\n",
    "                            print('-' * 40)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error {error_count} converting {file_path}: {e}\")\n",
    "                            error_count += 1\n",
    "                            pass\n",
    "\n",
    "                    else:\n",
    "                        # print(f\"Verified {file_path}\")\n",
    "                        jpg_count += 1\n",
    "\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Corrupted or unsupported image file: {file_path} - {e}\")\n",
    "\n",
    "    print(f\"{target_format}: {jpg_count} | other: {other_count} | error: {error_count} | total files: {jpg_count + other_count}\")\n",
    "\n",
    "# Verify and convert images in the training and validation directories\n",
    "verify_and_convert_images('data/train')\n",
    "verify_and_convert_images('data/test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
